### Kaggle-titanic
This is a tutorial in an IPython Notebook for the Kaggle competition, Titanic Machine Learning From Disaster. The goal of this repository is to provide an example of a competitive analysis for those interested in getting into the field of data analytics or using python for Kaggle's Data Science competitions .

>This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning."

From the competition [homepage](http://www.kaggle.com/c/titanic-gettingStarted).


### Goal for this Notebook:
Show a simple example of an analysis of the Titanic disaster in Python and implementation of Full stack Data Science project.

## Table of Content

1. **Hypothesis Generation**

2.**Data Exploration (EDA)**

![](/images/univariate.png) Univariate Analysis

![](/images/univariate_1.png) 

![](/images/bivariate.png) Bivariate Analysis

![](/images/bivariate_1.png) 

![](/images/bivariate_2.png) 

![](/images/bivariate_3.png) 

3. **Data Cleaning & Feature Engineering**

![](/images/feature_engineering.png) 

![](/images/feature_engineering_1.png) 

4. **Model Building.**
- In Model Building i have created a function which performs cross-validation along with test-predictions.
- I have experimented with many Classification algorithms.
- **Random Forest** gave the best accuracy score-> *86%*

5. **Hyper-Parameter Tuning**
- In this I have used GridSearchCV along with Random Forest.

6. **Re-training model using the Hyper parameter**
- After Re-training my model using the Hyper parameter.
- I was able to achieve an accuracy of **88%**.
